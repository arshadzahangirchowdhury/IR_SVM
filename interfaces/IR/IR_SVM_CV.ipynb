{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "@author: M Arshad Zahangir Chowdhury\n",
    "\n",
    "SVM cross-validations based on pressure and concentrations\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "%matplotlib inline \n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import signal\n",
    "from ipywidgets import interactive\n",
    "import seaborn as sns  #heat map\n",
    "import glob # batch processing of images\n",
    "\n",
    "if '../../' not in sys.path:\n",
    "    sys.path.append('../../')\n",
    "\n",
    "from src.spectral_datasets.IR_datasets import IR_data\n",
    "\n",
    "\n",
    "from src.misc.utils import *\n",
    "\n",
    "import datetime\n",
    "\n",
    "#import metrics to evaluate classifiers\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "\n",
    "# from sklearn.metrics import roc_curve\n",
    "# https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.multiclass import OneVsRestClassifier \n",
    "\n",
    "from scipy import interpolate\n",
    "from sys import getsizeof\n",
    "\n",
    "path_exp = \"../../data/IR_Experimental_Data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Front trim : 0.0\n",
      "End trim : 0.0\n",
      "Number of Compounds: 34\n",
      "Number of Spectrum: 10\n",
      "Total Number of Spectra: 340\n",
      "Front trim : 0.0\n",
      "End trim : 0.0\n",
      "Data Start Input: 400\n",
      "Data End Input: 4000\n",
      "Sample Size of training data: 3601\n",
      "Rows discarded: 0\n",
      "Resolution (1/cm) =  1.0\n",
      "\n",
      " labels of molecules present \n",
      " ['H2O', 'CO2', 'O3', 'N2O', 'CO', 'CH4', 'NO', 'SO2', 'NO2', 'NH3', 'HNO3', 'HF', 'HCl', 'HBr', 'HI', 'OCS', 'H2CO', 'HOCl', 'HCN', 'CH3Cl', 'H2O2', 'C2H2', 'C2H6', 'PH3', 'H2S', 'HCOOH', 'C2H4', 'CH3OH', 'CH3Br', 'CH3CN', 'C4H2', 'HC3N', 'SO3', 'COCl2']\n",
      "\n",
      " target indices (integers) of molecules present [ 0  0  0  0  0  0  0  0  0  0  1  1  1  1  1  1  1  1  1  1  2  2  2  2\n",
      "  2  2  2  2  2  2  3  3  3  3  3  3  3  3  3  3  4  4  4  4  4  4  4  4\n",
      "  4  4  5  5  5  5  5  5  5  5  5  5  6  6  6  6  6  6  6  6  6  6  7  7\n",
      "  7  7  7  7  7  7  7  7  8  8  8  8  8  8  8  8  8  8  9  9  9  9  9  9\n",
      "  9  9  9  9 10 10 10 10 10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11\n",
      " 12 12 12 12 12 12 12 12 12 12 13 13 13 13 13 13 13 13 13 13 14 14 14 14\n",
      " 14 14 14 14 14 14 15 15 15 15 15 15 15 15 15 15 16 16 16 16 16 16 16 16\n",
      " 16 16 17 17 17 17 17 17 17 17 17 17 18 18 18 18 18 18 18 18 18 18 19 19\n",
      " 19 19 19 19 19 19 19 19 20 20 20 20 20 20 20 20 20 20 21 21 21 21 21 21\n",
      " 21 21 21 21 22 22 22 22 22 22 22 22 22 22 23 23 23 23 23 23 23 23 23 23\n",
      " 24 24 24 24 24 24 24 24 24 24 25 25 25 25 25 25 25 25 25 25 26 26 26 26\n",
      " 26 26 26 26 26 26 27 27 27 27 27 27 27 27 27 27 28 28 28 28 28 28 28 28\n",
      " 28 28 29 29 29 29 29 29 29 29 29 29 30 30 30 30 30 30 30 30 30 30 31 31\n",
      " 31 31 31 31 31 31 31 31 32 32 32 32 32 32 32 32 32 32 33 33 33 33 33 33\n",
      " 33 33 33 33]\n",
      "\n",
      " frequencies present in the data \n",
      "  [ 400.  401.  402. ... 3998. 3999. 4000.]\n"
     ]
    }
   ],
   "source": [
    "s = IR_data(data_start = 400, data_end = 4000, resolution=1, verbosity = False, cv_type = 'pressure')\n",
    "s.load_IR_data()\n",
    "print('Number of Compounds:', s.n_compounds)\n",
    "print('Number of Spectrum:', s.n_spectrum)\n",
    "print('Total Number of Spectra:', s.n_spectra)\n",
    "print(\"Front trim :\", s.front_trim_amount)\n",
    "print(\"End trim :\", s.end_trim_amount)\n",
    "print('Data Start Input:',s.data_start)\n",
    "print('Data End Input:',s.data_end)           \n",
    "print('Sample Size of training data:', s.samplesize )\n",
    "print('Rows discarded:', s.n_discard_rows)\n",
    "print('Resolution (1/cm) = ', s.resolution)\n",
    "\n",
    "print('\\n labels of molecules present \\n', s.labels)\n",
    "print('\\n target indices (integers) of molecules present', s.targets)\n",
    "print('\\n frequencies present in the data \\n ', s.frequencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of features: (340, 3601)\n",
      "shape of labels: (340,)\n"
     ]
    }
   ],
   "source": [
    "X = s.spectra\n",
    "y = s.targets\n",
    "labels = s.labels\n",
    "n_compounds = s.n_compounds\n",
    "n_spectrum = s.n_spectrum\n",
    "n_spectra = s.n_compounds*s.n_spectrum\n",
    "samplesize = s.samplesize\n",
    "wavenumbers = s.frequencies\n",
    "print('shape of features:', X.shape)\n",
    "print('shape of labels:', y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pressure Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold number:  1\n",
      "\n",
      "\n",
      "----\n",
      "\n",
      "TEST INDICES\n",
      "      0\n",
      "0     0\n",
      "1    10\n",
      "2    20\n",
      "3    30\n",
      "4    40\n",
      "5    50\n",
      "6    60\n",
      "7    70\n",
      "8    80\n",
      "9    90\n",
      "10  100\n",
      "11  110\n",
      "12  120\n",
      "13  130\n",
      "14  140\n",
      "15  150\n",
      "16  160\n",
      "17  170\n",
      "18  180\n",
      "19  190\n",
      "20  200\n",
      "21  210\n",
      "22  220\n",
      "23  230\n",
      "24  240\n",
      "25  250\n",
      "26  260\n",
      "27  270\n",
      "28  280\n",
      "29  290\n",
      "30  300\n",
      "31  310\n",
      "32  320\n",
      "33  330\n",
      "Fold number:  2\n",
      "\n",
      "\n",
      "----\n",
      "\n",
      "TEST INDICES\n",
      "      0\n",
      "0     1\n",
      "1    11\n",
      "2    21\n",
      "3    31\n",
      "4    41\n",
      "5    51\n",
      "6    61\n",
      "7    71\n",
      "8    81\n",
      "9    91\n",
      "10  101\n",
      "11  111\n",
      "12  121\n",
      "13  131\n",
      "14  141\n",
      "15  151\n",
      "16  161\n",
      "17  171\n",
      "18  181\n",
      "19  191\n",
      "20  201\n",
      "21  211\n",
      "22  221\n",
      "23  231\n",
      "24  241\n",
      "25  251\n",
      "26  261\n",
      "27  271\n",
      "28  281\n",
      "29  291\n",
      "30  301\n",
      "31  311\n",
      "32  321\n",
      "33  331\n",
      "Fold number:  3\n",
      "\n",
      "\n",
      "----\n",
      "\n",
      "TEST INDICES\n",
      "      0\n",
      "0     2\n",
      "1    12\n",
      "2    22\n",
      "3    32\n",
      "4    42\n",
      "5    52\n",
      "6    62\n",
      "7    72\n",
      "8    82\n",
      "9    92\n",
      "10  102\n",
      "11  112\n",
      "12  122\n",
      "13  132\n",
      "14  142\n",
      "15  152\n",
      "16  162\n",
      "17  172\n",
      "18  182\n",
      "19  192\n",
      "20  202\n",
      "21  212\n",
      "22  222\n",
      "23  232\n",
      "24  242\n",
      "25  252\n",
      "26  262\n",
      "27  272\n",
      "28  282\n",
      "29  292\n",
      "30  302\n",
      "31  312\n",
      "32  322\n",
      "33  332\n",
      "Fold number:  4\n",
      "\n",
      "\n",
      "----\n",
      "\n",
      "TEST INDICES\n",
      "      0\n",
      "0     3\n",
      "1    13\n",
      "2    23\n",
      "3    33\n",
      "4    43\n",
      "5    53\n",
      "6    63\n",
      "7    73\n",
      "8    83\n",
      "9    93\n",
      "10  103\n",
      "11  113\n",
      "12  123\n",
      "13  133\n",
      "14  143\n",
      "15  153\n",
      "16  163\n",
      "17  173\n",
      "18  183\n",
      "19  193\n",
      "20  203\n",
      "21  213\n",
      "22  223\n",
      "23  233\n",
      "24  243\n",
      "25  253\n",
      "26  263\n",
      "27  273\n",
      "28  283\n",
      "29  293\n",
      "30  303\n",
      "31  313\n",
      "32  323\n",
      "33  333\n",
      "Fold number:  5\n",
      "\n",
      "\n",
      "----\n",
      "\n",
      "TEST INDICES\n",
      "      0\n",
      "0     4\n",
      "1    14\n",
      "2    24\n",
      "3    34\n",
      "4    44\n",
      "5    54\n",
      "6    64\n",
      "7    74\n",
      "8    84\n",
      "9    94\n",
      "10  104\n",
      "11  114\n",
      "12  124\n",
      "13  134\n",
      "14  144\n",
      "15  154\n",
      "16  164\n",
      "17  174\n",
      "18  184\n",
      "19  194\n",
      "20  204\n",
      "21  214\n",
      "22  224\n",
      "23  234\n",
      "24  244\n",
      "25  254\n",
      "26  264\n",
      "27  274\n",
      "28  284\n",
      "29  294\n",
      "30  304\n",
      "31  314\n",
      "32  324\n",
      "33  334\n",
      "Fold number:  6\n",
      "\n",
      "\n",
      "----\n",
      "\n",
      "TEST INDICES\n",
      "      0\n",
      "0     5\n",
      "1    15\n",
      "2    25\n",
      "3    35\n",
      "4    45\n",
      "5    55\n",
      "6    65\n",
      "7    75\n",
      "8    85\n",
      "9    95\n",
      "10  105\n",
      "11  115\n",
      "12  125\n",
      "13  135\n",
      "14  145\n",
      "15  155\n",
      "16  165\n",
      "17  175\n",
      "18  185\n",
      "19  195\n",
      "20  205\n",
      "21  215\n",
      "22  225\n",
      "23  235\n",
      "24  245\n",
      "25  255\n",
      "26  265\n",
      "27  275\n",
      "28  285\n",
      "29  295\n",
      "30  305\n",
      "31  315\n",
      "32  325\n",
      "33  335\n",
      "Fold number:  7\n",
      "\n",
      "\n",
      "----\n",
      "\n",
      "TEST INDICES\n",
      "      0\n",
      "0     6\n",
      "1    16\n",
      "2    26\n",
      "3    36\n",
      "4    46\n",
      "5    56\n",
      "6    66\n",
      "7    76\n",
      "8    86\n",
      "9    96\n",
      "10  106\n",
      "11  116\n",
      "12  126\n",
      "13  136\n",
      "14  146\n",
      "15  156\n",
      "16  166\n",
      "17  176\n",
      "18  186\n",
      "19  196\n",
      "20  206\n",
      "21  216\n",
      "22  226\n",
      "23  236\n",
      "24  246\n",
      "25  256\n",
      "26  266\n",
      "27  276\n",
      "28  286\n",
      "29  296\n",
      "30  306\n",
      "31  316\n",
      "32  326\n",
      "33  336\n",
      "Fold number:  8\n",
      "\n",
      "\n",
      "----\n",
      "\n",
      "TEST INDICES\n",
      "      0\n",
      "0     7\n",
      "1    17\n",
      "2    27\n",
      "3    37\n",
      "4    47\n",
      "5    57\n",
      "6    67\n",
      "7    77\n",
      "8    87\n",
      "9    97\n",
      "10  107\n",
      "11  117\n",
      "12  127\n",
      "13  137\n",
      "14  147\n",
      "15  157\n",
      "16  167\n",
      "17  177\n",
      "18  187\n",
      "19  197\n",
      "20  207\n",
      "21  217\n",
      "22  227\n",
      "23  237\n",
      "24  247\n",
      "25  257\n",
      "26  267\n",
      "27  277\n",
      "28  287\n",
      "29  297\n",
      "30  307\n",
      "31  317\n",
      "32  327\n",
      "33  337\n",
      "Fold number:  9\n",
      "\n",
      "\n",
      "----\n",
      "\n",
      "TEST INDICES\n",
      "      0\n",
      "0     8\n",
      "1    18\n",
      "2    28\n",
      "3    38\n",
      "4    48\n",
      "5    58\n",
      "6    68\n",
      "7    78\n",
      "8    88\n",
      "9    98\n",
      "10  108\n",
      "11  118\n",
      "12  128\n",
      "13  138\n",
      "14  148\n",
      "15  158\n",
      "16  168\n",
      "17  178\n",
      "18  188\n",
      "19  198\n",
      "20  208\n",
      "21  218\n",
      "22  228\n",
      "23  238\n",
      "24  248\n",
      "25  258\n",
      "26  268\n",
      "27  278\n",
      "28  288\n",
      "29  298\n",
      "30  308\n",
      "31  318\n",
      "32  328\n",
      "33  338\n",
      "Fold number:  10\n",
      "\n",
      "\n",
      "----\n",
      "\n",
      "TEST INDICES\n",
      "      0\n",
      "0     9\n",
      "1    19\n",
      "2    29\n",
      "3    39\n",
      "4    49\n",
      "5    59\n",
      "6    69\n",
      "7    79\n",
      "8    89\n",
      "9    99\n",
      "10  109\n",
      "11  119\n",
      "12  129\n",
      "13  139\n",
      "14  149\n",
      "15  159\n",
      "16  169\n",
      "17  179\n",
      "18  189\n",
      "19  199\n",
      "20  209\n",
      "21  219\n",
      "22  229\n",
      "23  239\n",
      "24  249\n",
      "25  259\n",
      "26  269\n",
      "27  279\n",
      "28  289\n",
      "29  299\n",
      "30  309\n",
      "31  319\n",
      "32  329\n",
      "33  339\n"
     ]
    }
   ],
   "source": [
    "#See what is in each fold\n",
    "\n",
    "#Create Stratified k-fold\n",
    "\n",
    "\n",
    "totalnumber_folds=10\n",
    "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
    "\n",
    "# train_X.shape\n",
    "# train_X_df = pd.DataFrame(train_X)\n",
    "\n",
    "skf = StratifiedKFold(n_splits=totalnumber_folds,random_state=None, shuffle=False)\n",
    "skf.get_n_splits(X, y)\n",
    "\n",
    "#print(skf)\n",
    "\n",
    "\n",
    "#Intialize fold counter before looping through them\n",
    "foldcounter=0\n",
    "Fold_number=np.array([])\n",
    "Fold_Times=np.array([])\n",
    "Fold_Class_Acc=np.array([])\n",
    "Fold_Class_Precision=np.array([])\n",
    "Fold_Class_Recall=np.array([])\n",
    "Fold_Class_F1=np.array([])\n",
    "\n",
    "\n",
    "\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    foldcounter+=1\n",
    "    print(\"Fold number: \", foldcounter)\n",
    "    print(\"\\n\")\n",
    "    #print(\"TRAIN:\", train_index)\n",
    "    #print(\"TEST:\", test_index)\n",
    "    train_index_DF=pd.DataFrame(train_index)\n",
    "    test_index_DF=pd.DataFrame(test_index)\n",
    "#     print('TRAIN INDICES')\n",
    "#     print(train_index_DF)\n",
    "    print('----\\n')\n",
    "    print('TEST INDICES')\n",
    "    print(test_index_DF)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_index_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold  1\n",
      "Fold  2\n",
      "Fold  3\n",
      "Fold  4\n",
      "Fold  5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/reshad812/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold  6\n",
      "Fold  7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/reshad812/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/reshad812/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/reshad812/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold  8\n",
      "Fold  9\n",
      "Fold  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/reshad812/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Stratfied OVR(SVM-Linear)\n",
    "\n",
    "#Intialize fold counter before looping through them\n",
    "foldcounter=0\n",
    "Fold_number=np.array([])\n",
    "Fold_Times=np.array([])\n",
    "Fold_Class_Acc=np.array([])\n",
    "Fold_Class_Precision=np.array([])\n",
    "Fold_Class_Recall=np.array([])\n",
    "Fold_Class_F1=np.array([])\n",
    "\n",
    "\n",
    "\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    foldcounter+=1\n",
    "    #print(\"TRAIN:\", train_index)\n",
    "    #print(\"TEST:\", test_index)\n",
    "    train_index_DF=pd.DataFrame(train_index)\n",
    "    test_index_DF=pd.DataFrame(test_index)\n",
    "#     print('TRAIN INDICES')\n",
    "#     print(train_index_DF)\n",
    "#     print('TEST INDICES')\n",
    "#     print(test_index_DF)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "           \n",
    "    #now comes the learning or fitting inside the folds\n",
    "\n",
    "    print('Fold ', foldcounter)\n",
    "    \n",
    "    #OneVsRest (SVM-Linear)\n",
    "\n",
    "    #Measure time elapsed\n",
    "    import datetime\n",
    "    t_start = datetime.datetime.now()\n",
    "\n",
    "    from sklearn.multiclass import OneVsRestClassifier #Shift + tab will show detains of the classifier\n",
    "    from sklearn.svm import SVC\n",
    "\n",
    "    classifier_OVR = OneVsRestClassifier(SVC(kernel='linear',C = 500,decision_function_shape = 'ovo',random_state=1)).fit(X_train, y_train)\n",
    "\n",
    "\n",
    "    pred_y = classifier_OVR.predict(X_test)\n",
    "\n",
    "    # Turn on classifier internals to see misclassification indices\n",
    "    #classifier_internals(pred_y,test_y, train_y, 'OneVsRest')\n",
    "\n",
    "\n",
    "    cm_OVR = confusion_matrix(y_test, pred_y)\n",
    "    #print(cm_OVR)\n",
    "    fig = plt.figure(figsize=(16,10));\n",
    "#     plt.title('Confusion matrix (P = 0.5-16.5 torr, T=296 K) \\n Broad OVR(SVM) molecule-classifier(x=1)\\nFold '+str(foldcounter));\n",
    "    plt.title('OVR(Support Vector Machine-Linear) \\nIteration '+str(foldcounter));\n",
    "    ax = sns.heatmap(cm_OVR,linewidths=2, annot=True, cmap='RdPu');   #cmap='PiYG' also good\n",
    "    #ax = sns.heatmap(cm/np.sum(cm), annot=True, fmt='.2%', cmap='Blues') #Shows percentage\n",
    "    ax.set_xticklabels(labels);\n",
    "    ax.set_yticklabels(labels);\n",
    "    plt.xlabel('Predicted Molecule');\n",
    "    plt.ylabel('Actual Moelcule');\n",
    "    plt.xticks(rotation=90);\n",
    "    plt.yticks(rotation=0);\n",
    "\n",
    "\n",
    "    t_end = datetime.datetime.now()\n",
    "    delta = t_end - t_start\n",
    "    Time_OVR=delta.total_seconds() * 1000\n",
    "\n",
    "#     print('Time elaspsed: ', Time_OVR) # milliseconds\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    plt.savefig('KFOLDFIGURES/CM_OVR_SVM-Linear_P'+ str(foldcounter) + '.png',bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    Fold_number=np.append(Fold_number,[foldcounter], axis=0)\n",
    "    Fold_Times=np.append(Fold_Times,[Time_OVR], axis=0)\n",
    "    Fold_Class_Acc=np.append(Fold_Class_Acc,[accuracy_score(y_test, pred_y)], axis=0)\n",
    "    Fold_Class_Precision=np.append(Fold_Class_Precision,[(precision_score(y_test, pred_y, labels=[0],average='micro')\n",
    "                                                          + precision_score(y_test, pred_y, labels=[1],average='micro')\n",
    "                                                          + precision_score(y_test, pred_y, labels=[2],average='micro')\n",
    "                                                          + precision_score(y_test, pred_y, labels=[3],average='micro')\n",
    "                                                          + precision_score(y_test, pred_y, labels=[4],average='micro')\n",
    "                                                          + precision_score(y_test, pred_y, labels=[5],average='micro')\n",
    "                                                          + precision_score(y_test, pred_y, labels=[6],average='micro')\n",
    "                                                          + precision_score(y_test, pred_y, labels=[7],average='micro')\n",
    "                                                          + precision_score(y_test, pred_y, labels=[8],average='micro')\n",
    "                                                          + precision_score(y_test, pred_y, labels=[9],average='micro')\n",
    "                                                          + precision_score(y_test, pred_y, labels=[10],average='micro')\n",
    "                                                          + precision_score(y_test, pred_y, labels=[11],average='micro')\n",
    "                                                          + precision_score(y_test, pred_y, labels=[12],average='micro')\n",
    "                                                          + precision_score(y_test, pred_y, labels=[13],average='micro')\n",
    "                                                          + precision_score(y_test, pred_y, labels=[14],average='micro')\n",
    "                                                          + precision_score(y_test, pred_y, labels=[15],average='micro')\n",
    "                                                          + precision_score(y_test, pred_y, labels=[16],average='micro')\n",
    "                                                          + precision_score(y_test, pred_y, labels=[17],average='micro')\n",
    "                                                          + precision_score(y_test, pred_y, labels=[18],average='micro')\n",
    "                                                          + precision_score(y_test, pred_y, labels=[19],average='micro')\n",
    "                                                          + precision_score(y_test, pred_y, labels=[20],average='micro')\n",
    "                                                          + precision_score(y_test, pred_y, labels=[21],average='micro')\n",
    "                                                          + precision_score(y_test, pred_y, labels=[22],average='micro')\n",
    "                                                          + precision_score(y_test, pred_y, labels=[23],average='micro')\n",
    "                                                          + precision_score(y_test, pred_y, labels=[24],average='micro')\n",
    "                                                          + precision_score(y_test, pred_y, labels=[25],average='micro')\n",
    "                                                          + precision_score(y_test, pred_y, labels=[26],average='micro')\n",
    "                                                          + precision_score(y_test, pred_y, labels=[27],average='micro')\n",
    "                                                          + precision_score(y_test, pred_y, labels=[28],average='micro')\n",
    "                                                          + precision_score(y_test, pred_y, labels=[29],average='micro')\n",
    "                                                          + precision_score(y_test, pred_y, labels=[30],average='micro')\n",
    "                                                          + precision_score(y_test, pred_y, labels=[31],average='micro')\n",
    "                                                          + precision_score(y_test, pred_y, labels=[32],average='micro')\n",
    "                                                          + precision_score(y_test, pred_y, labels=[33],average='micro')\n",
    "                                                          \n",
    "                                                          )/n_compounds\n",
    "                                                        \n",
    "                                                        ], axis=0)\n",
    "    Fold_Class_Recall=np.append(Fold_Class_Recall,[(recall_score(y_test, pred_y, labels=[0],average='micro')\n",
    "                                                          + recall_score(y_test, pred_y, labels=[1],average='micro')\n",
    "                                                          + recall_score(y_test, pred_y, labels=[2],average='micro')\n",
    "                                                          + recall_score(y_test, pred_y, labels=[3],average='micro')\n",
    "                                                          + recall_score(y_test, pred_y, labels=[4],average='micro')\n",
    "                                                          + recall_score(y_test, pred_y, labels=[5],average='micro')\n",
    "                                                          + recall_score(y_test, pred_y, labels=[6],average='micro')\n",
    "                                                          + recall_score(y_test, pred_y, labels=[7],average='micro')\n",
    "                                                          + recall_score(y_test, pred_y, labels=[8],average='micro')\n",
    "                                                          + recall_score(y_test, pred_y, labels=[9],average='micro')\n",
    "                                                          + recall_score(y_test, pred_y, labels=[10],average='micro')\n",
    "                                                          + recall_score(y_test, pred_y, labels=[11],average='micro')\n",
    "                                                          + recall_score(y_test, pred_y, labels=[12],average='micro')\n",
    "                                                          + recall_score(y_test, pred_y, labels=[13],average='micro')\n",
    "                                                          + recall_score(y_test, pred_y, labels=[14],average='micro')\n",
    "                                                          + recall_score(y_test, pred_y, labels=[15],average='micro')\n",
    "                                                          + recall_score(y_test, pred_y, labels=[16],average='micro')                                                    \n",
    "                                                          + recall_score(y_test, pred_y, labels=[17],average='micro')\n",
    "                                                          + recall_score(y_test, pred_y, labels=[18],average='micro')\n",
    "                                                          + recall_score(y_test, pred_y, labels=[19],average='micro')\n",
    "                                                          + recall_score(y_test, pred_y, labels=[20],average='micro')\n",
    "                                                          + recall_score(y_test, pred_y, labels=[21],average='micro')\n",
    "                                                          + recall_score(y_test, pred_y, labels=[22],average='micro')\n",
    "                                                          + recall_score(y_test, pred_y, labels=[23],average='micro')\n",
    "                                                          + recall_score(y_test, pred_y, labels=[24],average='micro')\n",
    "                                                          + recall_score(y_test, pred_y, labels=[25],average='micro')\n",
    "                                                          + recall_score(y_test, pred_y, labels=[26],average='micro')\n",
    "                                                          + recall_score(y_test, pred_y, labels=[27],average='micro')\n",
    "                                                          + recall_score(y_test, pred_y, labels=[28],average='micro')\n",
    "                                                          + recall_score(y_test, pred_y, labels=[29],average='micro')\n",
    "                                                          + recall_score(y_test, pred_y, labels=[30],average='micro')\n",
    "                                                          + recall_score(y_test, pred_y, labels=[31],average='micro')\n",
    "                                                          + recall_score(y_test, pred_y, labels=[32],average='micro')\n",
    "                                                          + recall_score(y_test, pred_y, labels=[33],average='micro')\n",
    "                                                          )/n_compounds\n",
    "                                                        \n",
    "                                                        ], axis=0)\n",
    "    \n",
    "    Fold_Class_F1=np.append(Fold_Class_F1,[(f1_score(y_test, pred_y, labels=[0],average='micro')\n",
    "                                                          + f1_score(y_test, pred_y, labels=[1],average='micro')\n",
    "                                                          + f1_score(y_test, pred_y, labels=[2],average='micro')\n",
    "                                                          + f1_score(y_test, pred_y, labels=[3],average='micro')\n",
    "                                                          + f1_score(y_test, pred_y, labels=[4],average='micro')\n",
    "                                                          + f1_score(y_test, pred_y, labels=[5],average='micro')\n",
    "                                                          + f1_score(y_test, pred_y, labels=[6],average='micro')\n",
    "                                                          + f1_score(y_test, pred_y, labels=[7],average='micro')\n",
    "                                                          + f1_score(y_test, pred_y, labels=[8],average='micro')\n",
    "                                                          + f1_score(y_test, pred_y, labels=[9],average='micro')\n",
    "                                                          + f1_score(y_test, pred_y, labels=[10],average='micro')\n",
    "                                                          + f1_score(y_test, pred_y, labels=[11],average='micro')\n",
    "                                                          + f1_score(y_test, pred_y, labels=[12],average='micro')\n",
    "                                                          + f1_score(y_test, pred_y, labels=[13],average='micro')\n",
    "                                                          + f1_score(y_test, pred_y, labels=[14],average='micro')\n",
    "                                                          + f1_score(y_test, pred_y, labels=[15],average='micro')\n",
    "                                                          + f1_score(y_test, pred_y, labels=[16],average='micro')\n",
    "                                                          + f1_score(y_test, pred_y, labels=[17],average='micro')\n",
    "                                                          + f1_score(y_test, pred_y, labels=[18],average='micro')\n",
    "                                                          + f1_score(y_test, pred_y, labels=[19],average='micro')\n",
    "                                                          + f1_score(y_test, pred_y, labels=[20],average='micro')\n",
    "                                                          + f1_score(y_test, pred_y, labels=[21],average='micro')\n",
    "                                                          + f1_score(y_test, pred_y, labels=[22],average='micro')\n",
    "                                                          + f1_score(y_test, pred_y, labels=[23],average='micro')\n",
    "                                                          + f1_score(y_test, pred_y, labels=[24],average='micro')\n",
    "                                                          + f1_score(y_test, pred_y, labels=[25],average='micro')\n",
    "                                                          + f1_score(y_test, pred_y, labels=[26],average='micro')\n",
    "                                                          + f1_score(y_test, pred_y, labels=[27],average='micro')\n",
    "                                                          + f1_score(y_test, pred_y, labels=[28],average='micro')\n",
    "                                                          + f1_score(y_test, pred_y, labels=[29],average='micro')\n",
    "                                                          + f1_score(y_test, pred_y, labels=[30],average='micro')\n",
    "                                                          + f1_score(y_test, pred_y, labels=[31],average='micro')\n",
    "                                                          + f1_score(y_test, pred_y, labels=[32],average='micro')\n",
    "                                                          + f1_score(y_test, pred_y, labels=[33],average='micro')\n",
    "                                                   )/n_compounds\n",
    "                                                        \n",
    "                                                        ], axis=0)\n",
    "    \n",
    "\n",
    "\n",
    "kfoldResults_OVR_SVM = pd.DataFrame({'Method': 'OVR(SVM-Linear)',\n",
    "                             'Fold number': Fold_number,\n",
    "                             'Time': Fold_Times,\n",
    "                             'Accuracy': Fold_Class_Acc,\n",
    "                             'Average Precision': Fold_Class_Precision,\n",
    "                             'Average Recall': Fold_Class_Recall,\n",
    "                             'Average F1 score': Fold_Class_F1\n",
    "                            })\n",
    "\n",
    "\n",
    "plt.scatter(Fold_Class_Recall,Fold_Class_Precision);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method</th>\n",
       "      <th>Fold number</th>\n",
       "      <th>Time</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Average Precision</th>\n",
       "      <th>Average Recall</th>\n",
       "      <th>Average F1 score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OVR(SVM-Linear)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1131.129</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OVR(SVM-Linear)</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1129.948</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OVR(SVM-Linear)</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1189.142</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OVR(SVM-Linear)</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1012.509</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OVR(SVM-Linear)</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1196.052</td>\n",
       "      <td>0.970588</td>\n",
       "      <td>0.955882</td>\n",
       "      <td>0.970588</td>\n",
       "      <td>0.960784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>OVR(SVM-Linear)</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1256.154</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>OVR(SVM-Linear)</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1022.309</td>\n",
       "      <td>0.911765</td>\n",
       "      <td>0.867647</td>\n",
       "      <td>0.911765</td>\n",
       "      <td>0.882353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>OVR(SVM-Linear)</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1006.546</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>OVR(SVM-Linear)</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1310.737</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>OVR(SVM-Linear)</td>\n",
       "      <td>10.0</td>\n",
       "      <td>991.742</td>\n",
       "      <td>0.970588</td>\n",
       "      <td>0.955882</td>\n",
       "      <td>0.970588</td>\n",
       "      <td>0.960784</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Method  Fold number      Time  Accuracy  Average Precision  \\\n",
       "0  OVR(SVM-Linear)          1.0  1131.129  1.000000           1.000000   \n",
       "1  OVR(SVM-Linear)          2.0  1129.948  1.000000           1.000000   \n",
       "2  OVR(SVM-Linear)          3.0  1189.142  1.000000           1.000000   \n",
       "3  OVR(SVM-Linear)          4.0  1012.509  1.000000           1.000000   \n",
       "4  OVR(SVM-Linear)          5.0  1196.052  0.970588           0.955882   \n",
       "5  OVR(SVM-Linear)          6.0  1256.154  1.000000           1.000000   \n",
       "6  OVR(SVM-Linear)          7.0  1022.309  0.911765           0.867647   \n",
       "7  OVR(SVM-Linear)          8.0  1006.546  1.000000           1.000000   \n",
       "8  OVR(SVM-Linear)          9.0  1310.737  1.000000           1.000000   \n",
       "9  OVR(SVM-Linear)         10.0   991.742  0.970588           0.955882   \n",
       "\n",
       "   Average Recall  Average F1 score  \n",
       "0        1.000000          1.000000  \n",
       "1        1.000000          1.000000  \n",
       "2        1.000000          1.000000  \n",
       "3        1.000000          1.000000  \n",
       "4        0.970588          0.960784  \n",
       "5        1.000000          1.000000  \n",
       "6        0.911765          0.882353  \n",
       "7        1.000000          1.000000  \n",
       "8        1.000000          1.000000  \n",
       "9        0.970588          0.960784  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#append results from all folds\n",
    "kfoldResults = pd.DataFrame({})\n",
    "\n",
    "\n",
    "kfoldResults = kfoldResults.append(kfoldResults_OVR_SVM, ignore_index=True)\n",
    "\n",
    "\n",
    "# kfoldResults.to_csv('kfoldResults_P' +'.csv', index=False)\n",
    "kfoldResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Front trim : 0.0\n",
      "End trim : 0.0\n",
      "Number of Compounds: 34\n",
      "Number of Spectrum: 7\n",
      "Total Number of Spectra: 238\n",
      "Front trim : 0.0\n",
      "End trim : 0.0\n",
      "Data Start Input: 400\n",
      "Data End Input: 4000\n",
      "Sample Size of training data: 3601\n",
      "Rows discarded: 0\n",
      "Resolution (1/cm) =  1.0\n",
      "\n",
      " labels of molecules present \n",
      " ['H2O', 'CO2', 'O3', 'N2O', 'CO', 'CH4', 'NO', 'SO2', 'NO2', 'NH3', 'HNO3', 'HF', 'HCl', 'HBr', 'HI', 'OCS', 'H2CO', 'HOCl', 'HCN', 'CH3Cl', 'H2O2', 'C2H2', 'C2H6', 'PH3', 'H2S', 'HCOOH', 'C2H4', 'CH3OH', 'CH3Br', 'CH3CN', 'C4H2', 'HC3N', 'SO3', 'COCl2']\n",
      "\n",
      " target indices (integers) of molecules present [ 0  0  0  0  0  0  0  1  1  1  1  1  1  1  2  2  2  2  2  2  2  3  3  3\n",
      "  3  3  3  3  4  4  4  4  4  4  4  5  5  5  5  5  5  5  6  6  6  6  6  6\n",
      "  6  7  7  7  7  7  7  7  8  8  8  8  8  8  8  9  9  9  9  9  9  9 10 10\n",
      " 10 10 10 10 10 11 11 11 11 11 11 11 12 12 12 12 12 12 12 13 13 13 13 13\n",
      " 13 13 14 14 14 14 14 14 14 15 15 15 15 15 15 15 16 16 16 16 16 16 16 17\n",
      " 17 17 17 17 17 17 18 18 18 18 18 18 18 19 19 19 19 19 19 19 20 20 20 20\n",
      " 20 20 20 21 21 21 21 21 21 21 22 22 22 22 22 22 22 23 23 23 23 23 23 23\n",
      " 24 24 24 24 24 24 24 25 25 25 25 25 25 25 26 26 26 26 26 26 26 27 27 27\n",
      " 27 27 27 27 28 28 28 28 28 28 28 29 29 29 29 29 29 29 30 30 30 30 30 30\n",
      " 30 31 31 31 31 31 31 31 32 32 32 32 32 32 32 33 33 33 33 33 33 33]\n",
      "\n",
      " frequencies present in the data \n",
      "  [ 400.  401.  402. ... 3998. 3999. 4000.]\n"
     ]
    }
   ],
   "source": [
    "s = IR_data(data_start = 400, data_end = 4000, resolution=1, verbosity = False, cv_type = 'concentration')\n",
    "s.load_IR_data()\n",
    "print('Number of Compounds:', s.n_compounds)\n",
    "print('Number of Spectrum:', s.n_spectrum)\n",
    "print('Total Number of Spectra:', s.n_spectra)\n",
    "print(\"Front trim :\", s.front_trim_amount)\n",
    "print(\"End trim :\", s.end_trim_amount)\n",
    "print('Data Start Input:',s.data_start)\n",
    "print('Data End Input:',s.data_end)           \n",
    "print('Sample Size of training data:', s.samplesize )\n",
    "print('Rows discarded:', s.n_discard_rows)\n",
    "print('Resolution (1/cm) = ', s.resolution)\n",
    "\n",
    "print('\\n labels of molecules present \\n', s.labels)\n",
    "print('\\n target indices (integers) of molecules present', s.targets)\n",
    "print('\\n frequencies present in the data \\n ', s.frequencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of features: (238, 3601)\n",
      "shape of labels: (238,)\n"
     ]
    }
   ],
   "source": [
    "X = s.spectra\n",
    "y = s.targets\n",
    "labels = s.labels\n",
    "n_compounds = s.n_compounds\n",
    "n_spectrum = s.n_spectrum\n",
    "n_spectra = s.n_compounds*s.n_spectrum\n",
    "samplesize = s.samplesize\n",
    "wavenumbers = s.frequencies\n",
    "print('shape of features:', X.shape)\n",
    "print('shape of labels:', y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold number:  1\n",
      "\n",
      "\n",
      "----\n",
      "\n",
      "TEST INDICES\n",
      "      0\n",
      "0     0\n",
      "1     7\n",
      "2    14\n",
      "3    21\n",
      "4    28\n",
      "5    35\n",
      "6    42\n",
      "7    49\n",
      "8    56\n",
      "9    63\n",
      "10   70\n",
      "11   77\n",
      "12   84\n",
      "13   91\n",
      "14   98\n",
      "15  105\n",
      "16  112\n",
      "17  119\n",
      "18  126\n",
      "19  133\n",
      "20  140\n",
      "21  147\n",
      "22  154\n",
      "23  161\n",
      "24  168\n",
      "25  175\n",
      "26  182\n",
      "27  189\n",
      "28  196\n",
      "29  203\n",
      "30  210\n",
      "31  217\n",
      "32  224\n",
      "33  231\n",
      "Fold number:  2\n",
      "\n",
      "\n",
      "----\n",
      "\n",
      "TEST INDICES\n",
      "      0\n",
      "0     1\n",
      "1     8\n",
      "2    15\n",
      "3    22\n",
      "4    29\n",
      "5    36\n",
      "6    43\n",
      "7    50\n",
      "8    57\n",
      "9    64\n",
      "10   71\n",
      "11   78\n",
      "12   85\n",
      "13   92\n",
      "14   99\n",
      "15  106\n",
      "16  113\n",
      "17  120\n",
      "18  127\n",
      "19  134\n",
      "20  141\n",
      "21  148\n",
      "22  155\n",
      "23  162\n",
      "24  169\n",
      "25  176\n",
      "26  183\n",
      "27  190\n",
      "28  197\n",
      "29  204\n",
      "30  211\n",
      "31  218\n",
      "32  225\n",
      "33  232\n",
      "Fold number:  3\n",
      "\n",
      "\n",
      "----\n",
      "\n",
      "TEST INDICES\n",
      "      0\n",
      "0     2\n",
      "1     9\n",
      "2    16\n",
      "3    23\n",
      "4    30\n",
      "5    37\n",
      "6    44\n",
      "7    51\n",
      "8    58\n",
      "9    65\n",
      "10   72\n",
      "11   79\n",
      "12   86\n",
      "13   93\n",
      "14  100\n",
      "15  107\n",
      "16  114\n",
      "17  121\n",
      "18  128\n",
      "19  135\n",
      "20  142\n",
      "21  149\n",
      "22  156\n",
      "23  163\n",
      "24  170\n",
      "25  177\n",
      "26  184\n",
      "27  191\n",
      "28  198\n",
      "29  205\n",
      "30  212\n",
      "31  219\n",
      "32  226\n",
      "33  233\n",
      "Fold number:  4\n",
      "\n",
      "\n",
      "----\n",
      "\n",
      "TEST INDICES\n",
      "      0\n",
      "0     3\n",
      "1    10\n",
      "2    17\n",
      "3    24\n",
      "4    31\n",
      "5    38\n",
      "6    45\n",
      "7    52\n",
      "8    59\n",
      "9    66\n",
      "10   73\n",
      "11   80\n",
      "12   87\n",
      "13   94\n",
      "14  101\n",
      "15  108\n",
      "16  115\n",
      "17  122\n",
      "18  129\n",
      "19  136\n",
      "20  143\n",
      "21  150\n",
      "22  157\n",
      "23  164\n",
      "24  171\n",
      "25  178\n",
      "26  185\n",
      "27  192\n",
      "28  199\n",
      "29  206\n",
      "30  213\n",
      "31  220\n",
      "32  227\n",
      "33  234\n",
      "Fold number:  5\n",
      "\n",
      "\n",
      "----\n",
      "\n",
      "TEST INDICES\n",
      "      0\n",
      "0     4\n",
      "1    11\n",
      "2    18\n",
      "3    25\n",
      "4    32\n",
      "5    39\n",
      "6    46\n",
      "7    53\n",
      "8    60\n",
      "9    67\n",
      "10   74\n",
      "11   81\n",
      "12   88\n",
      "13   95\n",
      "14  102\n",
      "15  109\n",
      "16  116\n",
      "17  123\n",
      "18  130\n",
      "19  137\n",
      "20  144\n",
      "21  151\n",
      "22  158\n",
      "23  165\n",
      "24  172\n",
      "25  179\n",
      "26  186\n",
      "27  193\n",
      "28  200\n",
      "29  207\n",
      "30  214\n",
      "31  221\n",
      "32  228\n",
      "33  235\n",
      "Fold number:  6\n",
      "\n",
      "\n",
      "----\n",
      "\n",
      "TEST INDICES\n",
      "      0\n",
      "0     5\n",
      "1    12\n",
      "2    19\n",
      "3    26\n",
      "4    33\n",
      "5    40\n",
      "6    47\n",
      "7    54\n",
      "8    61\n",
      "9    68\n",
      "10   75\n",
      "11   82\n",
      "12   89\n",
      "13   96\n",
      "14  103\n",
      "15  110\n",
      "16  117\n",
      "17  124\n",
      "18  131\n",
      "19  138\n",
      "20  145\n",
      "21  152\n",
      "22  159\n",
      "23  166\n",
      "24  173\n",
      "25  180\n",
      "26  187\n",
      "27  194\n",
      "28  201\n",
      "29  208\n",
      "30  215\n",
      "31  222\n",
      "32  229\n",
      "33  236\n",
      "Fold number:  7\n",
      "\n",
      "\n",
      "----\n",
      "\n",
      "TEST INDICES\n",
      "      0\n",
      "0     6\n",
      "1    13\n",
      "2    20\n",
      "3    27\n",
      "4    34\n",
      "5    41\n",
      "6    48\n",
      "7    55\n",
      "8    62\n",
      "9    69\n",
      "10   76\n",
      "11   83\n",
      "12   90\n",
      "13   97\n",
      "14  104\n",
      "15  111\n",
      "16  118\n",
      "17  125\n",
      "18  132\n",
      "19  139\n",
      "20  146\n",
      "21  153\n",
      "22  160\n",
      "23  167\n",
      "24  174\n",
      "25  181\n",
      "26  188\n",
      "27  195\n",
      "28  202\n",
      "29  209\n",
      "30  216\n",
      "31  223\n",
      "32  230\n",
      "33  237\n"
     ]
    }
   ],
   "source": [
    "#See what is in each fold\n",
    "\n",
    "#Create Stratified k-fold\n",
    "\n",
    "\n",
    "totalnumber_folds=7\n",
    "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
    "\n",
    "# train_X.shape\n",
    "# train_X_df = pd.DataFrame(train_X)\n",
    "\n",
    "skf = StratifiedKFold(n_splits=totalnumber_folds,random_state=None, shuffle=False)\n",
    "skf.get_n_splits(X, y)\n",
    "\n",
    "#print(skf)\n",
    "\n",
    "\n",
    "#Intialize fold counter before looping through them\n",
    "foldcounter=0\n",
    "Fold_number=np.array([])\n",
    "Fold_Times=np.array([])\n",
    "Fold_Class_Acc=np.array([])\n",
    "Fold_Class_Precision=np.array([])\n",
    "Fold_Class_Recall=np.array([])\n",
    "Fold_Class_F1=np.array([])\n",
    "\n",
    "\n",
    "\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    foldcounter+=1\n",
    "    print(\"Fold number: \", foldcounter)\n",
    "    print(\"\\n\")\n",
    "    #print(\"TRAIN:\", train_index)\n",
    "    #print(\"TEST:\", test_index)\n",
    "    train_index_DF=pd.DataFrame(train_index)\n",
    "    test_index_DF=pd.DataFrame(test_index)\n",
    "#     print('TRAIN INDICES')\n",
    "#     print(train_index_DF)\n",
    "    print('----\\n')\n",
    "    print('TEST INDICES')\n",
    "    print(test_index_DF)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold  1\n",
      "Fold  2\n",
      "Fold  3\n",
      "Fold  4\n",
      "Fold  5\n",
      "Fold  6\n",
      "Fold  7\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Stratfied OVR(SVM-Linear)\n",
    "\n",
    "#Intialize fold counter before looping through them\n",
    "foldcounter=0\n",
    "Fold_number=np.array([])\n",
    "Fold_Times=np.array([])\n",
    "Fold_Class_Acc=np.array([])\n",
    "Fold_Class_Precision=np.array([])\n",
    "Fold_Class_Recall=np.array([])\n",
    "Fold_Class_F1=np.array([])\n",
    "\n",
    "\n",
    "\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    foldcounter+=1\n",
    "    #print(\"TRAIN:\", train_index)\n",
    "    #print(\"TEST:\", test_index)\n",
    "    train_index_DF=pd.DataFrame(train_index)\n",
    "    test_index_DF=pd.DataFrame(test_index)\n",
    "#     print('TRAIN INDICES')\n",
    "#     print(train_index_DF)\n",
    "#     print('TEST INDICES')\n",
    "#     print(test_index_DF)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "           \n",
    "    #now comes the learning or fitting inside the folds\n",
    "\n",
    "    print('Fold ', foldcounter)\n",
    "    \n",
    "    #OneVsRest (SVM-Linear)\n",
    "\n",
    "    #Measure time elapsed\n",
    "    import datetime\n",
    "    t_start = datetime.datetime.now()\n",
    "\n",
    "    from sklearn.multiclass import OneVsRestClassifier #Shift + tab will show detains of the classifier\n",
    "    from sklearn.svm import SVC\n",
    "\n",
    "    classifier_OVR = OneVsRestClassifier(SVC(kernel='linear',C = 500,decision_function_shape = 'ovo',random_state=1)).fit(X_train, y_train)\n",
    "\n",
    "\n",
    "    pred_y = classifier_OVR.predict(X_test)\n",
    "\n",
    "    # Turn on classifier internals to see misclassification indices\n",
    "    #classifier_internals(pred_y,test_y, train_y, 'OneVsRest')\n",
    "\n",
    "\n",
    "    cm_OVR = confusion_matrix(y_test, pred_y)\n",
    "    #print(cm_OVR)\n",
    "    fig = plt.figure(figsize=(16,10));\n",
    "#     plt.title('Confusion matrix (P = 0.5-16.5 torr, T=296 K) \\n Broad OVR(SVM) molecule-classifier(x=1)\\nFold '+str(foldcounter));\n",
    "    plt.title('OVR(Support Vector Machine-Linear) \\nIteration '+str(foldcounter));\n",
    "    ax = sns.heatmap(cm_OVR,linewidths=2, annot=True, cmap='RdPu');   #cmap='PiYG' also good\n",
    "    #ax = sns.heatmap(cm/np.sum(cm), annot=True, fmt='.2%', cmap='Blues') #Shows percentage\n",
    "    ax.set_xticklabels(labels);\n",
    "    ax.set_yticklabels(labels);\n",
    "    plt.xlabel('Predicted Molecule');\n",
    "    plt.ylabel('Actual Moelcule');\n",
    "    plt.xticks(rotation=90);\n",
    "    plt.yticks(rotation=0);\n",
    "\n",
    "\n",
    "    t_end = datetime.datetime.now()\n",
    "    delta = t_end - t_start\n",
    "    Time_OVR=delta.total_seconds() * 1000\n",
    "\n",
    "#     print('Time elaspsed: ', Time_OVR) # milliseconds\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    plt.savefig('KFOLDFIGURES/CM_OVR_SVM-Linear_X'+ str(foldcounter) + '.png',bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    Fold_number=np.append(Fold_number,[foldcounter], axis=0)\n",
    "    Fold_Times=np.append(Fold_Times,[Time_OVR], axis=0)\n",
    "    Fold_Class_Acc=np.append(Fold_Class_Acc,[accuracy_score(y_test, pred_y)], axis=0)\n",
    "    Fold_Class_Precision=np.append(Fold_Class_Precision,[(precision_score(y_test, pred_y, labels=[0],average='micro')\n",
    "                                                          + precision_score(y_test, pred_y, labels=[1],average='micro')\n",
    "                                                          + precision_score(y_test, pred_y, labels=[2],average='micro')\n",
    "                                                          + precision_score(y_test, pred_y, labels=[3],average='micro')\n",
    "                                                          + precision_score(y_test, pred_y, labels=[4],average='micro')\n",
    "                                                          + precision_score(y_test, pred_y, labels=[5],average='micro')\n",
    "                                                          + precision_score(y_test, pred_y, labels=[6],average='micro')\n",
    "                                                          + precision_score(y_test, pred_y, labels=[7],average='micro')\n",
    "                                                          + precision_score(y_test, pred_y, labels=[8],average='micro')\n",
    "                                                          + precision_score(y_test, pred_y, labels=[9],average='micro')\n",
    "                                                          + precision_score(y_test, pred_y, labels=[10],average='micro')\n",
    "                                                          + precision_score(y_test, pred_y, labels=[11],average='micro')\n",
    "                                                          + precision_score(y_test, pred_y, labels=[12],average='micro')\n",
    "                                                          + precision_score(y_test, pred_y, labels=[13],average='micro')\n",
    "                                                          + precision_score(y_test, pred_y, labels=[14],average='micro')\n",
    "                                                          + precision_score(y_test, pred_y, labels=[15],average='micro')\n",
    "                                                          + precision_score(y_test, pred_y, labels=[16],average='micro')\n",
    "                                                          + precision_score(y_test, pred_y, labels=[17],average='micro')\n",
    "                                                          + precision_score(y_test, pred_y, labels=[18],average='micro')\n",
    "                                                          + precision_score(y_test, pred_y, labels=[19],average='micro')\n",
    "                                                          + precision_score(y_test, pred_y, labels=[20],average='micro')\n",
    "                                                          + precision_score(y_test, pred_y, labels=[21],average='micro')\n",
    "                                                          + precision_score(y_test, pred_y, labels=[22],average='micro')\n",
    "                                                          + precision_score(y_test, pred_y, labels=[23],average='micro')\n",
    "                                                          + precision_score(y_test, pred_y, labels=[24],average='micro')\n",
    "                                                          + precision_score(y_test, pred_y, labels=[25],average='micro')\n",
    "                                                          + precision_score(y_test, pred_y, labels=[26],average='micro')\n",
    "                                                          + precision_score(y_test, pred_y, labels=[27],average='micro')\n",
    "                                                          + precision_score(y_test, pred_y, labels=[28],average='micro')\n",
    "                                                          + precision_score(y_test, pred_y, labels=[29],average='micro')\n",
    "                                                          + precision_score(y_test, pred_y, labels=[30],average='micro')\n",
    "                                                          + precision_score(y_test, pred_y, labels=[31],average='micro')\n",
    "                                                          + precision_score(y_test, pred_y, labels=[32],average='micro')\n",
    "                                                          + precision_score(y_test, pred_y, labels=[33],average='micro')\n",
    "                                                          \n",
    "                                                          )/n_compounds\n",
    "                                                        \n",
    "                                                        ], axis=0)\n",
    "    Fold_Class_Recall=np.append(Fold_Class_Recall,[(recall_score(y_test, pred_y, labels=[0],average='micro')\n",
    "                                                          + recall_score(y_test, pred_y, labels=[1],average='micro')\n",
    "                                                          + recall_score(y_test, pred_y, labels=[2],average='micro')\n",
    "                                                          + recall_score(y_test, pred_y, labels=[3],average='micro')\n",
    "                                                          + recall_score(y_test, pred_y, labels=[4],average='micro')\n",
    "                                                          + recall_score(y_test, pred_y, labels=[5],average='micro')\n",
    "                                                          + recall_score(y_test, pred_y, labels=[6],average='micro')\n",
    "                                                          + recall_score(y_test, pred_y, labels=[7],average='micro')\n",
    "                                                          + recall_score(y_test, pred_y, labels=[8],average='micro')\n",
    "                                                          + recall_score(y_test, pred_y, labels=[9],average='micro')\n",
    "                                                          + recall_score(y_test, pred_y, labels=[10],average='micro')\n",
    "                                                          + recall_score(y_test, pred_y, labels=[11],average='micro')\n",
    "                                                          + recall_score(y_test, pred_y, labels=[12],average='micro')\n",
    "                                                          + recall_score(y_test, pred_y, labels=[13],average='micro')\n",
    "                                                          + recall_score(y_test, pred_y, labels=[14],average='micro')\n",
    "                                                          + recall_score(y_test, pred_y, labels=[15],average='micro')\n",
    "                                                          + recall_score(y_test, pred_y, labels=[16],average='micro')                                                    \n",
    "                                                          + recall_score(y_test, pred_y, labels=[17],average='micro')\n",
    "                                                          + recall_score(y_test, pred_y, labels=[18],average='micro')\n",
    "                                                          + recall_score(y_test, pred_y, labels=[19],average='micro')\n",
    "                                                          + recall_score(y_test, pred_y, labels=[20],average='micro')\n",
    "                                                          + recall_score(y_test, pred_y, labels=[21],average='micro')\n",
    "                                                          + recall_score(y_test, pred_y, labels=[22],average='micro')\n",
    "                                                          + recall_score(y_test, pred_y, labels=[23],average='micro')\n",
    "                                                          + recall_score(y_test, pred_y, labels=[24],average='micro')\n",
    "                                                          + recall_score(y_test, pred_y, labels=[25],average='micro')\n",
    "                                                          + recall_score(y_test, pred_y, labels=[26],average='micro')\n",
    "                                                          + recall_score(y_test, pred_y, labels=[27],average='micro')\n",
    "                                                          + recall_score(y_test, pred_y, labels=[28],average='micro')\n",
    "                                                          + recall_score(y_test, pred_y, labels=[29],average='micro')\n",
    "                                                          + recall_score(y_test, pred_y, labels=[30],average='micro')\n",
    "                                                          + recall_score(y_test, pred_y, labels=[31],average='micro')\n",
    "                                                          + recall_score(y_test, pred_y, labels=[32],average='micro')\n",
    "                                                          + recall_score(y_test, pred_y, labels=[33],average='micro')\n",
    "                                                          )/n_compounds\n",
    "                                                        \n",
    "                                                        ], axis=0)\n",
    "    \n",
    "    Fold_Class_F1=np.append(Fold_Class_F1,[(f1_score(y_test, pred_y, labels=[0],average='micro')\n",
    "                                                          + f1_score(y_test, pred_y, labels=[1],average='micro')\n",
    "                                                          + f1_score(y_test, pred_y, labels=[2],average='micro')\n",
    "                                                          + f1_score(y_test, pred_y, labels=[3],average='micro')\n",
    "                                                          + f1_score(y_test, pred_y, labels=[4],average='micro')\n",
    "                                                          + f1_score(y_test, pred_y, labels=[5],average='micro')\n",
    "                                                          + f1_score(y_test, pred_y, labels=[6],average='micro')\n",
    "                                                          + f1_score(y_test, pred_y, labels=[7],average='micro')\n",
    "                                                          + f1_score(y_test, pred_y, labels=[8],average='micro')\n",
    "                                                          + f1_score(y_test, pred_y, labels=[9],average='micro')\n",
    "                                                          + f1_score(y_test, pred_y, labels=[10],average='micro')\n",
    "                                                          + f1_score(y_test, pred_y, labels=[11],average='micro')\n",
    "                                                          + f1_score(y_test, pred_y, labels=[12],average='micro')\n",
    "                                                          + f1_score(y_test, pred_y, labels=[13],average='micro')\n",
    "                                                          + f1_score(y_test, pred_y, labels=[14],average='micro')\n",
    "                                                          + f1_score(y_test, pred_y, labels=[15],average='micro')\n",
    "                                                          + f1_score(y_test, pred_y, labels=[16],average='micro')\n",
    "                                                          + f1_score(y_test, pred_y, labels=[17],average='micro')\n",
    "                                                          + f1_score(y_test, pred_y, labels=[18],average='micro')\n",
    "                                                          + f1_score(y_test, pred_y, labels=[19],average='micro')\n",
    "                                                          + f1_score(y_test, pred_y, labels=[20],average='micro')\n",
    "                                                          + f1_score(y_test, pred_y, labels=[21],average='micro')\n",
    "                                                          + f1_score(y_test, pred_y, labels=[22],average='micro')\n",
    "                                                          + f1_score(y_test, pred_y, labels=[23],average='micro')\n",
    "                                                          + f1_score(y_test, pred_y, labels=[24],average='micro')\n",
    "                                                          + f1_score(y_test, pred_y, labels=[25],average='micro')\n",
    "                                                          + f1_score(y_test, pred_y, labels=[26],average='micro')\n",
    "                                                          + f1_score(y_test, pred_y, labels=[27],average='micro')\n",
    "                                                          + f1_score(y_test, pred_y, labels=[28],average='micro')\n",
    "                                                          + f1_score(y_test, pred_y, labels=[29],average='micro')\n",
    "                                                          + f1_score(y_test, pred_y, labels=[30],average='micro')\n",
    "                                                          + f1_score(y_test, pred_y, labels=[31],average='micro')\n",
    "                                                          + f1_score(y_test, pred_y, labels=[32],average='micro')\n",
    "                                                          + f1_score(y_test, pred_y, labels=[33],average='micro')\n",
    "                                                   )/n_compounds\n",
    "                                                        \n",
    "                                                        ], axis=0)\n",
    "    \n",
    "\n",
    "\n",
    "kfoldResults_OVR_SVM = pd.DataFrame({'Method': 'OVR(SVM-Linear)',\n",
    "                             'Fold number': Fold_number,\n",
    "                             'Time': Fold_Times,\n",
    "                             'Accuracy': Fold_Class_Acc,\n",
    "                             'Average Precision': Fold_Class_Precision,\n",
    "                             'Average Recall': Fold_Class_Recall,\n",
    "                             'Average F1 score': Fold_Class_F1\n",
    "                            })\n",
    "\n",
    "\n",
    "plt.scatter(Fold_Class_Recall,Fold_Class_Precision);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method</th>\n",
       "      <th>Fold number</th>\n",
       "      <th>Time</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Average Precision</th>\n",
       "      <th>Average Recall</th>\n",
       "      <th>Average F1 score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OVR(SVM-Linear)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18847.783</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OVR(SVM-Linear)</td>\n",
       "      <td>2.0</td>\n",
       "      <td>26506.656</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OVR(SVM-Linear)</td>\n",
       "      <td>3.0</td>\n",
       "      <td>28632.285</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OVR(SVM-Linear)</td>\n",
       "      <td>4.0</td>\n",
       "      <td>14566.794</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OVR(SVM-Linear)</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9784.584</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>OVR(SVM-Linear)</td>\n",
       "      <td>6.0</td>\n",
       "      <td>26945.674</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>OVR(SVM-Linear)</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3167.594</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Method  Fold number       Time  Accuracy  Average Precision  \\\n",
       "0  OVR(SVM-Linear)          1.0  18847.783       1.0                1.0   \n",
       "1  OVR(SVM-Linear)          2.0  26506.656       1.0                1.0   \n",
       "2  OVR(SVM-Linear)          3.0  28632.285       1.0                1.0   \n",
       "3  OVR(SVM-Linear)          4.0  14566.794       1.0                1.0   \n",
       "4  OVR(SVM-Linear)          5.0   9784.584       1.0                1.0   \n",
       "5  OVR(SVM-Linear)          6.0  26945.674       1.0                1.0   \n",
       "6  OVR(SVM-Linear)          7.0   3167.594       1.0                1.0   \n",
       "\n",
       "   Average Recall  Average F1 score  \n",
       "0             1.0               1.0  \n",
       "1             1.0               1.0  \n",
       "2             1.0               1.0  \n",
       "3             1.0               1.0  \n",
       "4             1.0               1.0  \n",
       "5             1.0               1.0  \n",
       "6             1.0               1.0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#append results from all folds\n",
    "kfoldResults = pd.DataFrame({})\n",
    "\n",
    "\n",
    "kfoldResults = kfoldResults.append(kfoldResults_OVR_SVM, ignore_index=True)\n",
    "\n",
    "\n",
    "# kfoldResults.to_csv('kfoldResults_X' +'.csv', index=False)\n",
    "kfoldResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
